name: "Dotnet Test With Auto Retry"
description: "Runs dotnet test and retries failed tests once if there are less than 10 failed tests"
inputs:
  tests_filter:
    description: "Argument to pass to --filter"
    required: true
  test_results_file_name_prefix:
    description: "File name prefix to save results to. Should be in the form prefix-attempt-runattempt e.g. MyTestResults-attempt-2"
    required: true
  test_results_artifact_name_prefix:
    description: "The name of the artifact to create for the test results. Attempt number will be appended to this to make it unique across attempts"
    required: true
runs:
  using: "composite"
  steps:
    - name: Output dotnet info
      run: dotnet --info
      shell: bash

    - name: Restore SampleTests
      shell: bash
      run: |
          dotnet restore ./SampleTests/SampleTests.csproj --verbosity m

    - name: Build SampleTests
      shell: bash
      run: |
          dotnet build ./SampleTests/SampleTests.csproj --configuration Release --no-restore

    - name: Get previous run attempt
      shell: bash
      id: get-previous-run-attempt
      run:  |
            current_run_attempt=${{github.run_attempt}}
            previous_run_attempt=$(($current_run_attempt - 1))
            echo "previous_run_attempt=$previous_run_attempt" >> $GITHUB_OUTPUT

    - name: Get name of previous test results artifact
      shell: bash
      id: get-name-of-previous-test-results-artifact
      if: ${{ steps.get-previous-run-attempt.outputs.previous_run_attempt != '0' }}
      run:  |
            artifact_name="${{inputs.test_results_artifact_name_prefix}} Attempt-${{steps.get-previous-run-attempt.outputs.previous_run_attempt}}"
            echo "artifact_name=$artifact_name" >> $GITHUB_OUTPUT

    - name: Get name of test results artifact
      shell: bash
      id: get-name-of-test-results-artifact
      run:  |
            artifact_name="${{inputs.test_results_artifact_name_prefix}} Attempt-${{github.run_attempt}}"
            echo "artifact_name=$artifact_name" >> $GITHUB_OUTPUT

    # not only does this step download the artifact, it also extracts the files from the archive so we end up with the test results XML in the working folder
    - name: Download previous test results artifact
      uses: actions/download-artifact@v4
      if: ${{ steps.get-previous-run-attempt.outputs.previous_run_attempt != '0' }}
      continue-on-error: true # if we fail to download the archive for whatever reason then we should just proceed anyway and try to run all tests again
      with:
        name: ${{steps.get-name-of-previous-test-results-artifact.outputs.artifact_name}}

    - name: Check for tests not run
      shell: bash
      id: check-for-tests-not-run
      continue-on-error: true
      if: ${{ steps.get-previous-run-attempt.outputs.previous_run_attempt != '0' && success() }}
      run:  |
            # we want to make sure that all the tests passed into the filter on previous run were actually 
            # run. If we see the line "No test matches the given testcase filter" in the output then this means one of the filters 
            # didn't work and we didn't run all the required tests. So now we should run all the tests
            tests_not_run="0"

            if grep -q "No test matches the given testcase filter" ${{inputs.test_results_file_name_prefix}}.xml; then
                tests_not_run="1"
            fi

            echo "tests_not_run=$tests_not_run" >> $GITHUB_OUTPUT

    - name: Extract names of failed tests
      shell: bash
      id: extract_failed_tests
      continue-on-error: true
      if: ${{ steps.get-previous-run-attempt.outputs.previous_run_attempt != '0' && steps.check-for-tests-not-run.outputs.tests_not_run == '0' && success() }}
      run:  |
            sudo apt-get -y update
            sudo apt-get -y install libxml2-utils

            # xmllint doesn't properly support xml namespaces so in this case we just strip them out with sed
            sed -e 's/xmlns="[^"]*"//g' \
                    ${{inputs.test_results_file_name_prefix}}.xml | \
                    xmllint --xpath "//UnitTestResult[@outcome='Failed']/@testName" - > failed_tests.txt
            exit 1;

    - name: Get test filter
      id: get_test_filter
      shell: bash
      run: |
        default_test_filter="${{inputs.tests_filter}}" # default if there's no failed tests from last attempt
        tests_filter="${default_test_filter}"

        # check that the file with failed tests exists and the outcome of the previous step (extracting XML file was success)
        # the outcome check is important in the case where the previous step failed and bad output went into failed_tests.txt
        if [ -f "failed_tests.txt" ] && [ ${{steps.extract_failed_tests.outcome}} == "success" ]; then
            echo "Failed tests file exists."

            first_line=$(head -n 1 "failed_tests.txt")

            if [ "$first_line" != "XPath set is empty" ]; then
                # check the number of failures. If its more than 10, then we just rerun the whole lot
                number_of_lines=$(wc -l < "failed_tests.txt")

                if [ $(($number_of_lines)) -lt 11 ]; then
                    # reset the tests filter
                    tests_filter=""

                    while IFS= read -r failed_test_line; do \
                        echo "failed_test_line:$failed_test_line"

                        # beware any test names that have ellipses (иии or ...) - that means the xunit test runner has truncated the test name
                        # in these cases we should rerun the full set of tests because we don't know how to rerun tests that are truncated
                        # max display name length is MaximumDisplayNameLength = 447;
                        if [[ $failed_test_line == *"иии"* || $failed_test_line == *"..."* ]]; then
                           tests_filter="${default_test_filter}"
                           break
                        fi

                        failed_test=${failed_test_line:11} #strip testName=" from start of line
                        failed_test=${failed_test::-1} # strip trailing "

                        # need to replace XML quotes &quot; with \" (escaped quotes needed to work on the command line)
                        failed_test=$(echo "$failed_test" | sed 's/&quot;/\\"/g')

                        # need to escape any () with \(\) this is important for tests with inline data
                        # also in these cases we need to use displayname rather than fullyqualifiedname
                        filter_type="FullyQualifiedName"

                        if [[ $failed_test == *"("* ]]; then
                            echo "Found a parametrized test. We need to escape the ( and ) for dotnet test"

                            failed_test=$(echo "$failed_test" | sed 's/(/\\(/g')
                            failed_test=$(echo "$failed_test" | sed 's/)/\\)/g')

                            # for parametrized tests we need to use the DisplayName to filter
                            filter_type="DisplayName"
                        fi

                        tests_filter+="${filter_type}=${failed_test}|"
                    done < failed_tests.txt

                    last_char="${tests_filter: -1}"
                    if [[ "$last_char" == "|" ]]; then
                        tests_filter="${tests_filter%?}"  # Remove the trailing |
                    fi
                fi
            fi
        fi

        echo "tests_filter:${tests_filter}"
        echo "tests_filter=$tests_filter" >> $GITHUB_OUTPUT

    - name: Test SampleTests
      shell: bash
      run: |
        dotnet test ./SampleTests/SampleTests.csproj --configuration Release --no-restore --no-build --filter '${{steps.get_test_filter.outputs.tests_filter}}' --verbosity normal '-l:trx;LogFileName=${{inputs.test_results_file_name_prefix}}.xml' -- RunConfiguration.TreatNoTestsAsError=true

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ${{steps.get-name-of-test-results-artifact.outputs.artifact_name}}
        path: ./SampleTests/TestResults/${{inputs.test_results_file_name_prefix}}.xml

    - name: Check for unrunnable tests
      if: always()
      shell: bash
      run: |
        # we basically want to make sure that if we set the filter, all the tests passed into the filter to be rerun were actually 
        # run. If we see the line "No test matches the given testcase filter" in the output then this means one of the filters 
        # didn't work and we didn't run all the required tests. Then we should fail the job. On next rerun, we'll see this message
        # and just run all tests
        if grep -q "No test matches the given testcase filter" ./SampleTests/TestResults/${{inputs.test_results_file_name_prefix}}.xml; then
            # mark the job as failed
            exit 1;
        fi